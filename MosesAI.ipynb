{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MosesAI project\n",
    "\n",
    "1. Read all Talmud pages in a directory\n",
    "2. Send them to Pinecode\n",
    "3. Read Pinecone index\n",
    "4. For a query, find relevant documents\n",
    "5. Using Langchain, send the query and relevant documents to ChatGPT\n",
    "6. Get the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "MODEL=\"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "C_-uyi19vNjG",
    "outputId": "6f1fea63-559c-4763-b120-cbbd81a8291a"
   },
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "#from PIL import Image               # to load images\n",
    "#from IPython.display import display # to display images\n",
    "#pil_im = Image.open('/content/langchain and pinecone.png')\n",
    "#display(pil_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwalYTVZoRlH",
    "outputId": "9f475bea-721c-479f-c1fb-ea0ad263c9b7"
   },
   "outputs": [],
   "source": [
    "#!apt-get install poppler-utils  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AssnWUVlxtH"
   },
   "source": [
    "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/directory_loader.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fulYnj9nZr3n",
    "outputId": "2b9f6003-0b72-407a-de44-df9b7e216890"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "directory = 'data/talmud-pages/'\n",
    "\n",
    "def load_docs(directory):\n",
    "  loader = DirectoryLoader(directory)\n",
    "  documents = loader.load()\n",
    "  return documents\n",
    "\n",
    "documents = load_docs(directory)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwaCosqsogzw"
   },
   "source": [
    "https://python.langchain.com/en/latest/modules/indexes/text_splitters/getting_started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lF8jA6xZ0Hm",
    "outputId": "7fd4a04f-f80d-465b-a028-e8a611ebb9f4"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_docs(documents,chunk_size=1000,chunk_overlap=20):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "  docs = text_splitter.split_documents(documents)\n",
    "  return docs\n",
    "\n",
    "docs = split_docs(documents)\n",
    "print(len(docs))\n",
    "\n",
    "docs = documents\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVcFjgHJZ8S9",
    "outputId": "c8011cb1-9cd9-4223-ad71-60bbc83f9cbf"
   },
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5GY9voPa0av",
    "outputId": "5fd540c3-8e46-4863-aa07-8fcde3e0d822"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "\n",
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vySq5oI5sU5V"
   },
   "source": [
    "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/pinecone.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfIpYLV-acks"
   },
   "outputs": [],
   "source": [
    "import pinecone \n",
    "from langchain.vectorstores import Pinecone\n",
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'), \n",
    "    environment=\"us-central1-gcp\"  # next to api key in console\n",
    ")\n",
    "\n",
    "index_name = \"talmud-pages\"\n",
    "\n",
    "index = Pinecone.from_documents(docs, embeddings, index_name=index_name)\n",
    "\n",
    "# if you already have an index, you can load it like this\n",
    "index = Pinecone.from_existing_index(index_name, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5r7YLpbchAD",
    "outputId": "0433cb24-6adb-4daa-d629-337669379a0c"
   },
   "outputs": [],
   "source": [
    "def get_similiar_docs(query,k=5,score=False):\n",
    "  if score:\n",
    "    similar_docs = index.similarity_search_with_score(query,k=k)\n",
    "  else:\n",
    "    similar_docs = index.similarity_search(query,k=k)\n",
    "  return similar_docs\n",
    "\n",
    "query = \"When do you say Shema?\"\n",
    "similar_docs = get_similiar_docs(query)\n",
    "len(similar_docs)\n",
    "similar_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtF9QZSvbLD9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DuevPx4dbI4W",
    "outputId": "76a1ed52-c785-40a2-a0e9-828837972c18"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvqmkpJvss17"
   },
   "source": [
    "https://python.langchain.com/en/latest/use_cases/question_answering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "RqCE-C3Ubty0",
    "outputId": "f78b567f-5483-4ea9-90fb-3698ce1bf325"
   },
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "def get_answer(query):\n",
    "  similar_docs = get_similiar_docs(query)\n",
    "  # print(similar_docs)\n",
    "  answer =  chain.run(input_documents=similar_docs, question=query)\n",
    "  return  answer\n",
    "\n",
    "query = \"When to say Shema?\"  \n",
    "get_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "RTnCqRJ3r1kf",
    "outputId": "07b97326-64bf-4e25-9f61-a2eef3081784"
   },
   "outputs": [],
   "source": [
    "query = \"what are the sacrifices for? \\\n",
    "Sacrifices are typically brought for mistakes or unintentional transgressions, as stated in Keritot 9. \\\n",
    "However, there are cases when one brings an offering for intentional acts, such as relations with a slavewoman designated for another, a nazir who went to the cemetery, and one who swore a false oath of testimony (also mentioned in Keritot 9) \\\n",
    "what about bird sacrifices?\"\n",
    "get_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM+LlDQsGXPEHE1XTQC7Kf0",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
