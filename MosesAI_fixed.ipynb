{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22d3f44d",
   "metadata": {},
   "source": [
    "# MosesAI – RAG Pipeline (Fixed Imports)\n",
    "Generated 2025-05-23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a102568f",
   "metadata": {},
   "source": [
    "\n",
    "This notebook demonstrates a complete Retrieval‑Augmented Generation (RAG) pipeline **without** the\n",
    "`Pinecone.from_documents` attribute error.  \n",
    "It aliases the official Pinecone client and LangChain’s Pinecone vector‑store wrapper to avoid name collisions.\n",
    "\n",
    "```python\n",
    "from langchain.vectorstores import Pinecone as PineconeStore\n",
    "from pinecone import Pinecone as PineconeClient\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fe19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade langchain openai \"pinecone-client[grpc]\" tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d546353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os, pathlib\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Alias imports to avoid collision\n",
    "from langchain.vectorstores import Pinecone as PineconeStore\n",
    "from pinecone import Pinecone as PineconeClient\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "assert OPENAI_API_KEY and PINECONE_API_KEY, 'Add API keys to environment!'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0661dd6",
   "metadata": {},
   "source": [
    "## 1  Load & chunk documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff3b330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: 1 Chunks: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_DIR = pathlib.Path('sample_docs')\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "if not any(DATA_DIR.iterdir()):\n",
    "    (DATA_DIR / 'shema.txt').write_text(\n",
    "        'Hear, O Israel: the Lord our God, the Lord is one. Blessed be the name ...')\n",
    "\n",
    "loader = DirectoryLoader(str(DATA_DIR), loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=64)\n",
    "chunks = splitter.split_documents(docs)\n",
    "print('Docs:', len(docs), 'Chunks:', len(chunks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c656965",
   "metadata": {},
   "source": [
    "## 2  Embed & index in Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d1aa85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74174/672291771.py:1: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "client should be an instance of pinecone.Index, got <class 'pinecone.data.index.Index'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pc.list_indexes().names():\n\u001b[32m      7\u001b[39m     pc.create_index(index_name, dimension=dim, metric=\u001b[33m'\u001b[39m\u001b[33mcosine\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m vectorstore = \u001b[43mPineconeStore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_name\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mVectorstore ready\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/mark/data/markkerzner/MosesAI/myenv/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:848\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    846\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/mark/data/markkerzner/MosesAI/myenv/lib/python3.12/site-packages/langchain_community/vectorstores/pinecone.py:433\u001b[39m, in \u001b[36mPinecone.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, namespace, index_name, upsert_kwargs, pool_threads, embeddings_chunk_size, **kwargs)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    406\u001b[39m \u001b[33;03mDEPRECATED: use langchain_pinecone.PineconeVectorStore.from_texts instead:\u001b[39;00m\n\u001b[32m    407\u001b[39m \u001b[33;03mConstruct Pinecone wrapper from raw documents.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    430\u001b[39m \u001b[33;03m        )\u001b[39;00m\n\u001b[32m    431\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    432\u001b[39m pinecone_index = \u001b[38;5;28mcls\u001b[39m.get_pinecone_index(index_name, pool_threads)\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m pinecone = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpinecone_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m pinecone.add_texts(\n\u001b[32m    436\u001b[39m     texts,\n\u001b[32m    437\u001b[39m     metadatas=metadatas,\n\u001b[32m   (...)\u001b[39m\u001b[32m    442\u001b[39m     **(upsert_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    443\u001b[39m )\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pinecone\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/mark/data/markkerzner/MosesAI/myenv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:224\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    222\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    223\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/mark/data/markkerzner/MosesAI/myenv/lib/python3.12/site-packages/langchain_community/vectorstores/pinecone.py:73\u001b[39m, in \u001b[36mPinecone.__init__\u001b[39m\u001b[34m(self, index, embedding, text_key, namespace, distance_strategy)\u001b[39m\n\u001b[32m     68\u001b[39m     warnings.warn(\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing in `embedding` as a Callable is deprecated. Please pass in an\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Embeddings object instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m     )\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, pinecone.Index):\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     74\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mclient should be an instance of pinecone.Index, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m     )\n\u001b[32m     76\u001b[39m \u001b[38;5;28mself\u001b[39m._index = index\n\u001b[32m     77\u001b[39m \u001b[38;5;28mself\u001b[39m._embedding = embedding\n",
      "\u001b[31mValueError\u001b[39m: client should be an instance of pinecone.Index, got <class 'pinecone.data.index.Index'>"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "dim = len(embeddings.embed_query('ping'))\n",
    "\n",
    "pc = PineconeClient(api_key=PINECONE_API_KEY)\n",
    "index_name = 'talmud-pages'\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(index_name, dimension=dim, metric='cosine')\n",
    "\n",
    "vectorstore = PineconeStore.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name\n",
    ")\n",
    "print('Vectorstore ready')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3383261",
   "metadata": {},
   "source": [
    "## 3  Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad12290",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k':4})\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(qa({'query':'When do you say Shema?'})['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76fa442-d520-41f0-a8f6-da5d268094a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef59b22-77a5-4c8c-a1e5-4fa80dd03f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
