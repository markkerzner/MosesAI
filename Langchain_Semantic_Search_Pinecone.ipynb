{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MosesAI project\n",
    "\n",
    "1. Read all Talmud pages in a directory\n",
    "2. Send them to Pinecode\n",
    "3. Read Pinecone index\n",
    "4. For a query, find relevant documents\n",
    "5. Using Langchain, send the query and relevant documents to ChatGPT\n",
    "6. Get the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "MODEL=\"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "C_-uyi19vNjG",
    "outputId": "6f1fea63-559c-4763-b120-cbbd81a8291a"
   },
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "#from PIL import Image               # to load images\n",
    "#from IPython.display import display # to display images\n",
    "#pil_im = Image.open('/content/langchain and pinecone.png')\n",
    "#display(pil_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aYpmmfQ-ZbIh"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade langchain openai  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XbL5zdf9aG8a",
    "outputId": "60cf911c-3d70-4b71-edb0-4b04f8a6d6fa"
   },
   "outputs": [],
   "source": [
    "#!pip install unstructured -q\n",
    "#!pip install unstructured[local-inference] -q\n",
    "#!pip install detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwalYTVZoRlH",
    "outputId": "9f475bea-721c-479f-c1fb-ea0ad263c9b7"
   },
   "outputs": [],
   "source": [
    "#!apt-get install poppler-utils  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AssnWUVlxtH"
   },
   "source": [
    "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/directory_loader.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fulYnj9nZr3n",
    "outputId": "2b9f6003-0b72-407a-de44-df9b7e216890"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory not found: '../data/talmud-pages/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m   documents \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m documents\n\u001b[0;32m---> 10\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mload_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mlen\u001b[39m(documents)\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mload_docs\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_docs\u001b[39m(directory):\n\u001b[1;32m      6\u001b[0m   loader \u001b[38;5;241m=\u001b[39m DirectoryLoader(directory)\n\u001b[0;32m----> 7\u001b[0m   documents \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m documents\n",
      "File \u001b[0;32m~/anaconda3/envs/MosesAI/lib/python3.9/site-packages/langchain/document_loaders/directory.py:114\u001b[0m, in \u001b[0;36mDirectoryLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m p \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory not found: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected directory, got file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Directory not found: '../data/talmud-pages/'"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "directory = '../data/talmud-pages/'\n",
    "\n",
    "def load_docs(directory):\n",
    "  loader = DirectoryLoader(directory)\n",
    "  documents = loader.load()\n",
    "  return documents\n",
    "\n",
    "documents = load_docs(directory)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwaCosqsogzw"
   },
   "source": [
    "https://python.langchain.com/en/latest/modules/indexes/text_splitters/getting_started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lF8jA6xZ0Hm",
    "outputId": "7fd4a04f-f80d-465b-a028-e8a611ebb9f4"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_docs(documents,chunk_size=1000,chunk_overlap=20):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "  docs = text_splitter.split_documents(documents)\n",
    "  return docs\n",
    "\n",
    "docs = split_docs(documents)\n",
    "print(len(docs))\n",
    "\n",
    "docs = documents\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVcFjgHJZ8S9",
    "outputId": "c8011cb1-9cd9-4223-ad71-60bbc83f9cbf"
   },
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PiPwt-FaYwl"
   },
   "outputs": [],
   "source": [
    "#requires for open ai embedding\n",
    "#!pip install tiktoken -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5GY9voPa0av",
    "outputId": "5fd540c3-8e46-4863-aa07-8fcde3e0d822"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
    "\n",
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXhIY5SrrRec"
   },
   "outputs": [],
   "source": [
    "#!pip install pinecone-client -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vySq5oI5sU5V"
   },
   "source": [
    "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/pinecone.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfIpYLV-acks"
   },
   "outputs": [],
   "source": [
    "import pinecone \n",
    "from langchain.vectorstores import Pinecone\n",
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'), \n",
    "    # environment=\"us-west4-gcp-free\"  # next to api key in console\n",
    "    environment=\"us-central1-gcp\"  # next to api key in console\n",
    ")\n",
    "\n",
    "#index_name = \"langchain-demo\"\n",
    "index_name = \"talmud-pages\"\n",
    "\n",
    "index = Pinecone.from_documents(docs, embeddings, index_name=index_name)\n",
    "\n",
    "# if you already have an index, you can load it like this\n",
    "index = Pinecone.from_existing_index(index_name, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5r7YLpbchAD",
    "outputId": "0433cb24-6adb-4daa-d629-337669379a0c"
   },
   "outputs": [],
   "source": [
    "def get_similiar_docs(query,k=5,score=False):\n",
    "  if score:\n",
    "    similar_docs = index.similarity_search_with_score(query,k=k)\n",
    "  else:\n",
    "    similar_docs = index.similarity_search(query,k=k)\n",
    "  return similar_docs\n",
    "\n",
    "query = \"When do you say Shema?\"\n",
    "similar_docs = get_similiar_docs(query)\n",
    "len(similar_docs)\n",
    "similar_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtF9QZSvbLD9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DuevPx4dbI4W",
    "outputId": "76a1ed52-c785-40a2-a0e9-828837972c18"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvqmkpJvss17"
   },
   "source": [
    "https://python.langchain.com/en/latest/use_cases/question_answering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "RqCE-C3Ubty0",
    "outputId": "f78b567f-5483-4ea9-90fb-3698ce1bf325"
   },
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "def get_answer(query):\n",
    "  similar_docs = get_similiar_docs(query)\n",
    "  # print(similar_docs)\n",
    "  answer =  chain.run(input_documents=similar_docs, question=query)\n",
    "  return  answer\n",
    "\n",
    "query = \"When to say Shema?\"  \n",
    "get_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "RTnCqRJ3r1kf",
    "outputId": "07b97326-64bf-4e25-9f61-a2eef3081784"
   },
   "outputs": [],
   "source": [
    "query = \"what are the sacrifices for? \\\n",
    "Sacrifices are typically brought for mistakes or unintentional transgressions, as stated in Keritot 9. \\\n",
    "However, there are cases when one brings an offering for intentional acts, such as relations with a slavewoman designated for another, a nazir who went to the cemetery, and one who swore a false oath of testimony (also mentioned in Keritot 9) \\\n",
    "what about bird sacrifices?\"\n",
    "get_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM+LlDQsGXPEHE1XTQC7Kf0",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
